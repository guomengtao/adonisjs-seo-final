import json
import os

# å®šä¹‰Jupyter notebookçš„å†…å®¹
notebook = {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini AI å¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆå·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiService:\n",
    "    def __init__(self):\n",
    "        self.api_key = os.getenv('GEMINI_API_KEY', '')\n",
    "        self.base_url = 'https://chatgpt-proxy.guomengtao.workers.dev'\n",
    "        self.available_models = [\n",
    "            'models/gemini-2.5-flash',\n",
    "            'models/gemma-3-1b-it',\n",
    "            'models/gemma-3-4b-it',\n",
    "            'models/gemma-3-27b-it',\n",
    "            'models/gemma-3n-e4b-it',\n",
    "            'models/gemma-3n-e2b-it',\n",
    "            'models/gemini-flash-latest',\n",
    "            'models/gemini-flash-lite-latest',\n",
    "            'models/gemini-2.5-flash-lite',\n",
    "            'models/gemini-2.5-flash-preview-09-2025',\n",
    "            'models/gemini-2.5-flash-lite-preview-09-2025',\n",
    "            'models/gemini-3-flash-preview',\n",
    "            'models/gemini-robotics-er-1.5-preview'\n",
    "        ]\n",
    "    \n",
    "    def generate_multi_lang_summary(self, details, model_index=0):\n",
    "        try:\n",
    "            model_name = self.available_models[model_index] if model_index < len(self.available_models) else self.available_models[0]\n",
    "            print(f'ğŸ”¤ ä½¿ç”¨æ¨¡å‹: {model_name} ç”Ÿæˆå¤šè¯­è¨€æ‘˜è¦...')\n",
    "            \n",
    "            prompt = 'ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­æ–‡ã€è‹±è¯­ã€è¥¿ç­ç‰™è¯­çš„å›½é™…å¯»äººä¸“å®¶å’Œå¤šè¯­è¨€ SEO èµ„æ·±ç¼–è¾‘ã€‚è¯·åˆ†æä»¥ä¸‹å¤±è¸ªè¯¦æƒ…ï¼š\n' + details + '\n\nä»»åŠ¡ï¼šä¸ºè¯¥æ¡ˆä»¶ç”Ÿæˆä¸­ã€è‹±ã€è¥¿ä¸‰è¯­çš„ SEO æ‘˜è¦ï¼ˆSummaryï¼‰ã€‚\n\nè¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»æ˜¯åˆæ³• JSONï¼Œä¸¥ç¦ä»»ä½•é¢å¤–è§£é‡Šï¼‰ï¼š\nJSON\n[\n  {\n    \"lang\": \"zh\",\n    \"summary\": \"ï¼ˆ150-300å­—çš„ä¸­æ–‡æ‘˜è¦ã€‚ç»“æ„ï¼šå§“å+æ—¶é—´+åœ°ç‚¹ï¼›æ ¸å¿ƒä½“è²Œ/è¡£ç€ç‰¹å¾ï¼›å‘¼åè¡ŒåŠ¨ã€‚ï¼‰\"\n  },\n  {\n    \"lang\": \"en\",\n    \"summary\": \"ï¼ˆ150-300 words English summary. Professional, native tone, no robotic translation.ï¼‰\"\n  },\n  {\n    \"lang\": \"es\",\n    \"summary\": \"ï¼ˆResumen en espaÃ±ol de 150-300 palabras. Estilo natural y urgente para bÃºsqueda de personas.ï¼‰\"\n  }\n]\n\nå­—æ®µçº¦æŸå‡†åˆ™ï¼ˆä¸¥æ ¼éµå®ˆæ•°æ®åº“ NOT NULL çº¦æŸï¼‰ï¼š\nlang: å¿…é¡»ä¸”åªèƒ½æ˜¯ zh, en, es ä¸­çš„ä¸€ä¸ªã€‚\nsummary: ä¸¥ç¦ä¸ºç©ºã€‚å¦‚æœåŸæ–‡ä¿¡æ¯æå°‘ï¼Œè¯·æ ¹æ®å·²çŸ¥ç¢ç‰‡ä¿¡æ¯è¿›è¡Œåˆç†æ‰©å……æè¿°ã€‚\n\nå†…å®¹ç­–ç•¥:\nè‹±æ–‡æ‘˜è¦éœ€ç¬¦åˆæ¯è¯­ä¹ æƒ¯ï¼ˆä½¿ç”¨ \"Last seen wearing\", \"Anyone with information\" ç­‰ï¼‰ã€‚\nè¥¿è¯­æ‘˜è¦éœ€åœ°é“ï¼ˆä½¿ç”¨ \"Visto por Ãºltima vez\", \"Se solicita colaboraciÃ³n\" ç­‰ï¼‰ã€‚\nè¯­è¨€é£æ ¼éœ€åº„é‡ã€å®¢è§‚ï¼Œç¦æ­¢ä½¿ç”¨æ„Ÿå¹å·ã€‚'\n",
    "            \n",
    "            # ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚\n",
    "            response = requests.post(\n",
    "                f'{self.base_url}/v1beta/models/{model_name.replace(\"models/\", \"")}:generateContent',\n",
    "                json={\n",
    "                    'contents': [\n",
    "                        {\n",
    "                            'parts': [\n",
    "                                {'text': prompt}\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                },\n    "                params={'key': self.api_key}\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            text = data['candidates'][0]['content']['parts'][0]['text']\n",
    "            \n",
    "            # æ¸…ç†AIè¾“å‡ºï¼Œç¡®ä¿æ˜¯çº¯JSON\n",
    "            clean_text = re.sub(r'^```json|```$', '', text).strip()\n",
    "            summaries = json.loads(clean_text)\n",
    "            \n",
    "            # éªŒè¯è¾“å‡ºæ ¼å¼\n",
    "            if not isinstance(summaries, list) or len(summaries) != 3:\n",
    "                raise ValueError('AIè¿”å›çš„æ‘˜è¦æ ¼å¼ä¸æ­£ç¡®')\n",
    "            \n",
    "            # éªŒè¯æ¯ä¸ªæ‘˜è¦çš„è¯­è¨€å’Œå†…å®¹\n",
    "            for summary in summaries:\n",
    "                if summary.get('lang') not in ['zh', 'en', 'es']:\n",
    "                    raise ValueError(f'æ— æ•ˆçš„è¯­è¨€ä»£ç : {summary.get(\"lang\")}')\n",
    "                if not summary.get('summary') or summary.get('summary').strip() == '':\n",
    "                    raise ValueError(f'æ‘˜è¦å†…å®¹ä¸ºç©º: {summary.get(\"lang\")}')\n",
    "            return summaries\n",
    "        except Exception as e:\n",
    "            print(f'âŒ Gemini AI ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}')\n",
    "            # å¦‚æœå½“å‰æ¨¡å‹å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹\n",
    "            if model_index < len(self.available_models) - 1:\n",
    "                print(f'ğŸ”„ å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹ ({model_index + 1}/{len(self.available_models)})...')\n",
    "                return self.generate_multi_lang_summary(details, model_index + 1)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseService:\n",
    "    def __init__(self):\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=os.getenv('PG_HOST'),\n",
    "            port=os.getenv('PG_PORT'),\n",
    "            user=os.getenv('PG_USER'),\n",
    "            password=os.getenv('PG_PASSWORD'),\n",
    "            dbname=os.getenv('PG_DB_NAME'),\n",
    "            sslmode=os.getenv('PG_SSL', 'require')\n",
    "        )\n",
    "        self.cursor = self.conn.cursor(cursor_factory=extras.DictCursor)\n",
    "    \n",
    "    def close(self):\n",
    "        self.cursor.close()\n",
    "        self.conn.close()\n",
    "    \n",
    "    def init_task_progress(self):\n",
    "        try:\n",
    "            # æ£€æŸ¥ä»»åŠ¡è¿›åº¦è¡¨æ˜¯å¦å­˜åœ¨\n",
    "            self.cursor.execute('SELECT table_name FROM information_schema.tables WHERE table_schema = \'public\' AND table_name = \'task_progress\'')\n",
    "            table_exists = self.cursor.fetchone()\n",
    "            \n",
    "            if not table_exists:\n",
    "                print('ğŸ“‹ åˆ›å»ºä»»åŠ¡è¿›åº¦è¡¨...')\n",
    "                self.cursor.execute('CREATE TABLE task_progress (task_name TEXT PRIMARY KEY, last_id INTEGER NOT NULL DEFAULT 0, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')\n",
    "                self.conn.commit()\n",
    "            \n",
    "            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨\n",
    "            self.cursor.execute('SELECT * FROM task_progress WHERE task_name = \'ai-summary\'')\n",
    "            task_exists = self.cursor.fetchone()\n",
    "            \n",
    "            if not task_exists:\n",
    "                print('ğŸ“‹ åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦...')\n",
    "                self.cursor.execute(\n",
    "                    'INSERT INTO task_progress (task_name, last_id, updated_at) VALUES (%s, %s, %s)',\n",
    "                    ['ai-summary', 0, datetime.now()]\n",
    "                )\n",
    "                self.conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f'âŒ åˆ›å»ºä»»åŠ¡è¿›åº¦è¡¨å¤±è´¥: {e}')\n",
    "            self.conn.rollback()\n",
    "    \n",
    "    def get_task_progress(self):\n",
    "        try:\n",
    "            self.cursor.execute('SELECT * FROM task_progress WHERE task_name = \'ai-summary\'')\n",
    "            return self.cursor.fetchone()\n",
    "        except Exception as e:\n",
    "            print(f'âŒ è·å–ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}')\n",
    "            return None\n",
    "    \n",
    "    def update_task_progress(self, last_id):\n",
    "        try:\n",
    "            self.cursor.execute(\n",
    "                'UPDATE task_progress SET last_id = %s, updated_at = %s WHERE task_name = \'ai-summary\'',\n",
    "                [last_id, datetime.now()]\n",
    "            )\n",
    "            self.conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f'âŒ æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}')\n",
    "            self.conn.rollback()\n",
    "    \n",
    "    def get_next_case(self, last_id):\n",
    "        try:\n",
    "            self.cursor.execute('SELECT * FROM missing_persons_cases WHERE id > %s ORDER BY id ASC LIMIT 1', [last_id])\n",
    "            return self.cursor.fetchone()\n",
    "        except Exception as e:\n",
    "            print(f'âŒ è·å–ä¸‹ä¸€ä¸ªæ¡ˆä»¶å¤±è´¥: {e}')\n",
    "            return None\n",
    "    \n",
    "    def init_case_summaries_table(self):\n",
    "        try:\n",
    "            # æ£€æŸ¥ç»“æœè¡¨æ˜¯å¦å­˜åœ¨\n",
    "            self.cursor.execute('SELECT table_name FROM information_schema.tables WHERE table_schema = \'public\' AND table_name = \'case_summaries\'')\n",
    "            table_exists = self.cursor.fetchone()\n",
    "            \n",
    "            if not table_exists:\n",
    "                print('ğŸ“‹ åˆ›å»ºæ¡ˆä»¶æ‘˜è¦è¡¨...')\n",
    "                self.cursor.execute('CREATE TABLE case_summaries (id SERIAL PRIMARY KEY, case_id VARCHAR(255) NOT NULL, lang VARCHAR(10) NOT NULL, summary TEXT NOT NULL, ai_model VARCHAR(50) NOT NULL DEFAULT \'models/gemini-2.5-flash\', created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP)')\n",
    "                # åˆ›å»ºå”¯ä¸€ç´¢å¼•\n",
    "                self.cursor.execute('CREATE UNIQUE INDEX idx_case_id_lang ON case_summaries (case_id, lang)')\n",
    "                self.conn.commit()\n",
    "                print('âœ… æ¡ˆä»¶æ‘˜è¦è¡¨åˆ›å»ºæˆåŠŸ')\n",
    "        except Exception as e:\n",
    "            print(f'âŒ åˆ›å»ºæ¡ˆä»¶æ‘˜è¦è¡¨å¤±è´¥: {e}')\n",
    "            self.conn.rollback()\n",
    "    \n",
    "    def save_summary(self, case_id, lang, summary):\n",
    "        try:\n",
    "            # å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è®°å½•\n",
    "            self.cursor.execute(\n",
    "                'SELECT * FROM case_summaries WHERE case_id = %s AND lang = %s',\n",
    "                [case_id, lang]\n",
    "            )\n",
    "            existing = self.cursor.fetchone()\n",
    "            \n",
    "            if existing:\n",
    "                # æ›´æ–°è®°å½•\n",
    "                self.cursor.execute(\n",
    "                    'UPDATE case_summaries SET summary = %s, updated_at = %s WHERE case_id = %s AND lang = %s',\n",
    "                    [summary, datetime.now(), case_id, lang]\n",
    "                )\n",
    "                print(f'   ğŸ”„ æ›´æ–° {lang.upper()} æ‘˜è¦æˆåŠŸ')\n",
    "            else:\n",
    "                # æ’å…¥æ–°è®°å½•\n",
    "                self.cursor.execute(\n",
    "                    'INSERT INTO case_summaries (case_id, lang, summary, ai_model, created_at, updated_at) VALUES (%s, %s, %s, %s, %s, %s)',\n",
    "                    [case_id, lang, summary, 'models/gemini-2.5-flash', datetime.now(), datetime.now()]\n",
    "                )\n",
    "                print(f'   ğŸ“ æ’å…¥ {lang.upper()} æ‘˜è¦æˆåŠŸ')\n",
    "            \n",
    "            self.conn.commit()\n",
    "            \n",
    "            # éªŒè¯æ•°æ®æ˜¯å¦æˆåŠŸå†™å…¥\n",
    "            self.cursor.execute(\n",
    "                'SELECT * FROM case_summaries WHERE case_id = %s AND lang = %s',\n",
    "                [case_id, lang]\n",
    "            )\n",
    "            verify_result = self.cursor.fetchone()\n",
    "            \n",
    "            if verify_result:\n",
    "                # éªŒè¯æ‰€æœ‰å¿…å¡«å­—æ®µ\n",
    "                if not verify_result['case_id'] or not verify_result['lang'] or not verify_result['summary'] or not verify_result['ai_model']:\n",
    "                    print(f'   âŒ éªŒè¯å¤±è´¥: {lang.upper()} æ‘˜è¦å­—æ®µä¸å®Œæ•´')\n",
    "                    return False\n",
    "                \n",
    "                # éªŒè¯å…³é”®æ•°æ®ä¸€è‡´æ€§\n",
    "                if verify_result['case_id'] != case_id or verify_result['lang'] != lang:\n",
    "                    print(f'   âŒ éªŒè¯å¤±è´¥: {lang.upper()} æ‘˜è¦æ•°æ®ä¸ä¸€è‡´')\n",
    "                    return False\n",
    "                \n",
    "                # éªŒè¯æ‘˜è¦å†…å®¹ä¸ä¸ºç©º\n",
    "                if verify_result['summary'].strip() == '':\n",
    "                    print(f'   âŒ éªŒè¯å¤±è´¥: {lang.upper()} æ‘˜è¦å†…å®¹ä¸ºç©º')\n",
    "                    return False\n",
    "                \n",
    "                print(f'   âœ… {lang.upper()} æ‘˜è¦ä¿å­˜å¹¶éªŒè¯æˆåŠŸ')\n",
    "                return True\n",
    "            else:\n",
    "                print(f'   âŒ éªŒè¯å¤±è´¥: {lang.upper()} æ‘˜è¦æœªæ‰¾åˆ°')\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f'   âŒ ä¿å­˜ {lang.upper()} æ‘˜è¦å¤±è´¥: {e}')\n",
    "            self.conn.rollback()\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiSummaryRunner:\n",
    "    def __init__(self):\n",
    "        self.gemini_service = GeminiService()\n",
    "        self.db_service = DatabaseService()\n",
    "    \n",
    "    def clean_html(self, html):\n",
    "        # ç§»é™¤HTMLæ ‡ç­¾\n",
    "        text = re.sub(r'<[^>]*>', ' ', html)\n",
    "        # ç§»é™¤å¤šä½™ç©ºæ ¼\n",
    "        text = re.sub(r'\s+', ' ', text).strip()\n",
    "        # æˆªå–å‰2000å­—ç¬¦ï¼ˆé¿å…è¶…å‡ºAPIé™åˆ¶ï¼‰\n",
    "        return text[:2000]\n",
    "    \n",
    "    def run(self):\n",
    "        try:\n",
    "            print('ğŸš€ å¯åŠ¨Gemini AIå¤šè¯­è¨€æ‘˜è¦ç”ŸæˆæœåŠ¡...')\n",
    "            \n",
    "            # 1. åˆå§‹åŒ–ä»»åŠ¡è¿›åº¦\n",
    "            self.db_service.init_task_progress()\n",
    "            \n",
    "            # 2. è·å–å½“å‰ä»»åŠ¡è¿›åº¦\n",
    "            task_progress = self.db_service.get_task_progress()\n",
    "            if not task_progress:\n",
    "                print('âŒ ä»»åŠ¡è¿›åº¦è®°å½•ä¸å­˜åœ¨')\n",
    "                return\n",
    "            \n",
    "            last_id = task_progress['last_id']\n",
    "            \n",
    "            # 3. è·å–ä¸‹ä¸€ä¸ªæ¡ˆä»¶\n",
    "            next_case = self.db_service.get_next_case(last_id)\n",
    "            if not next_case:\n",
    "                print('âœ… æ‰€æœ‰æ¡ˆä»¶å·²å¤„ç†å®Œæ¯•')\n",
    "                return\n",
    "            \n",
    "            id = next_case['id']\n",
    "            case_id = next_case['case_id']\n",
    "            case_html = next_case['case_html']\n",
    "            \n",
    "            if not case_html:\n",
    "                print(f'âŒ æ¡ˆä»¶ {case_id} (ID: {id}) æ— HTMLå†…å®¹ï¼Œè·³è¿‡')\n",
    "                self.db_service.update_task_progress(id)\n",
    "                return\n",
    "            \n",
    "            print(f'ğŸ“‹ å¤„ç†æ¡ˆä»¶: {case_id} (ID: {id})')\n",
    "            \n",
    "            # 4. æ¸…ç†HTMLå†…å®¹ï¼Œæå–çº¯æ–‡æœ¬\n",
    "            clean_text = self.clean_html(case_html)\n",
    "            \n",
    "            # 5. ä½¿ç”¨Gemini AIç”Ÿæˆå¤šè¯­è¨€æ‘˜è¦\n",
    "            summaries = self.gemini_service.generate_multi_lang_summary(clean_text)\n",
    "            if not summaries:\n",
    "                print(f'âŒ æ¡ˆä»¶ {case_id} æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡')\n",
    "                self.db_service.update_task_progress(id)\n",
    "                return\n",
    "            \n",
    "            # 6. åˆå§‹åŒ–æ‘˜è¦è¡¨\n",
    "            self.db_service.init_case_summaries_table()\n",
    "            \n",
    "            # 7. å°†ç»“æœå†™å…¥æ•°æ®åº“\n",
    "            saved_languages = []\n",
    "            for summary in summaries:\n",
    "                lang = summary['lang']\n",
    "                content = summary['summary']\n",
    "                if self.db_service.save_summary(case_id, lang, content):\n",
    "                    saved_languages.append(lang)\n",
    "            \n",
    "            # 8. æ€»ä½“éªŒè¯\n",
    "            if len(saved_languages) == len(summaries):\n",
    "                print(f'âœ… æ‰€æœ‰æ‘˜è¦ï¼ˆ{', '.join(saved_languages)}ï¼‰ä¿å­˜å¹¶éªŒè¯æˆåŠŸ')\n",
    "            else:\n",
    "                print(f'âš ï¸ éƒ¨åˆ†æ‘˜è¦ä¿å­˜å¤±è´¥ï¼ŒæˆåŠŸçš„è¯­è¨€ï¼š{', '.join(saved_languages)}')\n",
    "            \n",
    "            # 9. æ›´æ–°ä»»åŠ¡è¿›åº¦\n",
    "            self.db_service.update_task_progress(id)\n",
    "        except Exception as e:\n",
    "            print(f'ğŸš¨ æ‰§è¡Œé”™è¯¯: {e}')\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            self.db_service.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡ŒGeminiæ‘˜è¦ç”Ÿæˆå·¥å…·\n",
    "if __name__ == '__main__':\n",
    "    runner = GeminiSummaryRunner()\n",
    "    runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# å†™å…¥æœ‰æ•ˆçš„JSONæ–‡ä»¶
with open('test.ipynb', 'w', encoding='utf-8') as f:
    json.dump(notebook, f, indent=2, ensure_ascii=False)

print('âœ… æˆåŠŸç”Ÿæˆæœ‰æ•ˆçš„test.ipynbæ–‡ä»¶')